# -*- coding: utf-8 -*-
"""
Created on Wed Apr  8 19:14:35 2020

@author: muril
"""

def get_mp(run_id,
           wd,
           wd_run,
           meta,
           res,
           dash_run,
           setup_nml,
           obs_type  = 'avg',
           time_idx  = ['year','doy','dap','das','date'],
           merge_idx = ['year','doy','sim_code'],
           save_res  = True):
    
    #-------------------------------------------------------#
    #------------------------ get_mp -----------------------# 
    #-------------------------------------------------------#
    #--- Goal: 
    #---    Merge simulated and observed data and compute model performance
    #--- Parameters: 
    #---    run_id      : Running ID
    #---    wd          : Working Directory
    #---    meta        : Meta information linking observed and simulated data      [dataframe]
    #---    res         : Results from JULES (e.g output from read_JULES_out())     [dictionary]
    #---    setup_nml   : A dataframe of nml setup file CSV generated by update_nml_setup() or provided
    #---    obs_type    : Type of observation to be used in the comparison
    #---    time_idx    : Time indexers
    #---    merge_idx   : Indexers used to merge simulated and observed data
    #--- Author:
    #---    Murilo Vianna (murilodsv@gmail.com)
    #-------------------------------------------------------#    

    print('\n!-------------------------!'+
          '\n!--- Model Performance ---!'+
          '\n!-------------------------!\n')
    
    import pandas as pd
    import gen_nml_defs       as gn    
    from get_model_perf import mperf
    from get_model_perf import find_var_res
    from get_model_perf import postproc_outputs
    from get_model_perf import get_conv_unitf
    from time import time
    
    #--- Track progress
    start_time = time()
    
    #-------------------------#
    #--- Read observations ---#
    #-------------------------#
    
    if 'obs_id' in dash_run.keys():
        
        #--- get obs_id
        obs_id = dash_run['obs_id'][dash_run['run_id']  == run_id].values[0]
        
        #--- check obs_id
        if obs_id == 'NA' or obs_id == float('nan'):
            obs_id = run_id
    else:
        obs_id = run_id
        
    #--- get observations
    print('Reading observations of "'+str(obs_id)+'" to compare with "'+str(run_id)+'" simulations.')
    obs     = gn.read_obs(obs_id,wd)
        
    #--- Filter observations to be compared with JULES
    sim = {}
    for k in obs.keys():
        if type(obs[k]) != type(None):
                                    
            #--- replace with run_id to merge with simulations
            if not obs_id == run_id: obs[k]['run_id'] = run_id                
                            
            #--- Merge observations with meta info
            obs[k] = pd.merge(obs[k], meta, on = 'variable')
            
            #--- filter observations
            if 'valid'      in obs[k].keys(): obs[k] = obs[k][:][obs[k]['valid']    == 1]           # Only valid flagged
            if 'obs_type'   in obs[k].keys(): obs[k] = obs[k][:][obs[k]['obs_type'] == obs_type]    # Only certain type: 'avg', 'msr', 'max',...            
            
            #--- drop observations that were not associated in the meta file (e.g. column 'sim_code')
            obs[k] = obs[k][:][~obs[k]['JULES_sim_code'].isnull()]             
            if len(obs[k]) == 0:
                #--- There is observation but is not associated with any jules outputs
                obs[k] = None
                sim    = {**sim, **{k:None}}
                continue
            
            #--- Rename columns
            obs[k] = obs[k].rename(columns = {'JULES_sim_code':'sim_code',
                                              'JULES_unit_fac':'unit_fac'})
    
            #--- List all JULES outputs found in metafile and observations
            l_obs_JULES = obs[k]['sim_code'].unique()
                            
            #--- Find variables in simulation results
            ini_res = True
            for v in l_obs_JULES:
                
                #--- lookup variable in raw outputs
                df_res_k = find_var_res(v,res,time_idx)
                
                #--- generate variable with raw outputs
                if type(df_res_k) == type(None):
                    print('Looking up for variable '+str(v)+' in postproc_outputs.py.')
                    df_res_k = postproc_outputs(v,
                                                res,
                                                dash_run,
                                                setup_nml,
                                                run_id,
                                                time_idx)
                
                if type(df_res_k) != type(None):
                    
                    #--- Get units and conversion factors from meta
                    conv_f = get_conv_unitf(v,
                                            meta)
                    
                    #--- convert units to same as observations
                    df_res_k['sim_value'] = df_res_k['sim_value'] * conv_f['conv_factor']
                    df_res_k['sim_units'] = conv_f['unit_lab']                    
                    
                    if ini_res:
                        df_res  = df_res_k
                        ini_res = False
                    else:
                        df_res = df_res.append(df_res_k)                
            
            if ini_res: df_res = None # none observed variable was found neither in raw outputs or postproc
            #--- Append to a dic
            sim    = {**sim, **{k:df_res}}
        else:
            #--- None Observations for this key
            sim    = {**sim, **{k:None}}    
    
    #------------------------------------------------------------------#
    #--- Merge simulated and observed data for performance analysis ---#
    #------------------------------------------------------------------#
    
    sim_obs = {}
    perf    = {}        
    for k in obs.keys():
        if (type(obs[k]) != type(None)) and (type(sim[k]) != type(None)):
            if k in sim.keys():
                                            
                if k == 'soil':
                    
                    #--- Match observed soil depth to simulated soil layers
                    from get_model_perf import merge_soil_data_by_layer
                                        
                    s_merg = merge_soil_data_by_layer(obs_df = obs[k],
                                                      sim_df = sim[k],
                                                      merge_idx = merge_idx)
                    
                    if type(s_merg) != type(None):
                        sim_obs_df  = s_merg['merged']
                        obs[k]      = s_merg['obs']
                        sim[k]      = s_merg['sim']
                    else:
                        sim_obs = {**sim_obs, **{k:None}}
                        perf    = {**perf   , **{k:None}}
                        continue       
                                        
                else:
                    #--- Merge simulated and observed data
                    sim_obs_df = pd.merge(obs[k],sim[k], how = 'left', on = merge_idx, suffixes=('_obs', '_sim'))
                
                #--- Drop any missing value
                sim_obs_df = sim_obs_df[:][~sim_obs_df['sim_value'].isnull()]                
                                                
                if len(sim_obs_df) == 0:
                    print('Warning: There is observed data for this run but dates do not match.\n - Please check if simulation dates match with observations.')
                    sim_obs = {**sim_obs, **{k:None}}
                    perf    = {**perf   , **{k:None}}
                    continue                    
                                
                #--- List of variables
                l_var = sim_obs_df['variable'].unique()
                
                #--- Calculate model performance for each variable
                init_perf = True
                for v in l_var:
                    
                    #--- Get performance as df
                    perf_v = pd.DataFrame(mperf(sim = sim_obs_df['sim_value'][sim_obs_df['variable'] == v],
                                                obs = sim_obs_df['obs_value'][sim_obs_df['variable'] == v],
                                                vnam   = v,
                                                dchart = False,
                                                outidx = "all"), index=[0])
                    
                    if init_perf:
                        perf_df   = perf_v
                        init_perf = False        
                    else:
                        perf_df = perf_df.append(perf_v)
                
                #--- Add run_id index
                perf_df['run_id'] = run_id
                
                #--- Store all results
                sim_obs = {**sim_obs, **{k:sim_obs_df}}
                perf    = {**perf   , **{k:perf_df}}
                
            else:                
                print('Warning: Simulations outputs does not have '+k+' results.\n - Failed to merge '+k+' simulated and observed data.')
                sim_obs = {**sim_obs, **{k:None}}
                perf    = {**perf   , **{k:None}}
        else:
            sim_obs = {**sim_obs, **{k:None}}
            perf    = {**perf   , **{k:None}}
    
    #--- Check status of performance run
    perf_stat = 1
    for k_s in sim_obs.keys():
        if type(sim_obs[k_s]) != type(None): perf_stat = 0
        
    #--- Gather Results
    results = {str(run_id)+'.obs'     : obs,
               str(run_id)+'.sim'     : sim,
               str(run_id)+'.sim_obs' : sim_obs,
               str(run_id)+'.perf'    : perf,
               str(run_id)+'.status'  : perf_stat}
        
    #--- Save results
    if save_res:
        for k in results.keys():
            if type(results[k]) != type(None) and k != str(run_id)+'.status':
                for k_r in results[k].keys():
                    if type(results[k][k_r]) != type(None):                        
                        results[k][k_r].to_csv(wd_run+'/namelists/output/'+k+'.'+k_r+'.csv', index = None, header=True)
    
    #--- track time
    print("Elapsed time: --- %.3f seconds ---" % (time() - start_time))
    
    #--- return
    return(results)
